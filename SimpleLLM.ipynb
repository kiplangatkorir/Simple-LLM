{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/tN03x3QA0UnccRBPsp9F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kiplangatkorir/Simple-LLM/blob/main/SimpleLLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KTZ80IBSU3LI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2be5edf0-9044-4be2-afeb-5bc561ab2ee0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 2.9607\n",
            "Epoch 2, Loss: 2.6111\n",
            "Epoch 3, Loss: 2.1844\n",
            "Epoch 4, Loss: 1.9966\n",
            "Epoch 5, Loss: 1.6182\n",
            "Epoch 6, Loss: 1.4319\n",
            "Epoch 7, Loss: 1.1322\n",
            "Epoch 8, Loss: 0.9247\n",
            "Epoch 9, Loss: 0.7245\n",
            "Epoch 10, Loss: 0.6320\n",
            "Epoch 11, Loss: 0.5237\n",
            "Epoch 12, Loss: 0.4015\n",
            "Epoch 13, Loss: 0.3568\n",
            "Epoch 14, Loss: 0.2897\n",
            "Epoch 15, Loss: 0.2436\n",
            "Epoch 16, Loss: 0.2513\n",
            "Epoch 17, Loss: 0.2161\n",
            "Epoch 18, Loss: 0.2285\n",
            "Epoch 19, Loss: 0.1989\n",
            "Epoch 20, Loss: 0.1883\n",
            "The king was kind and just. Every day, he would sit upon his throne and listen to the needs and concerns of his people.\n",
            "One day, a young traveler arrived at the palace gates. He carried a strange artifact\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "class SimpleDataset(Dataset):\n",
        "    def __init__(self, text, seq_length):\n",
        "        self.text = text\n",
        "        self.seq_length = seq_length\n",
        "        self.vocab = sorted(set(text))\n",
        "        self.char2idx = {c: i for i, c in enumerate(self.vocab)}\n",
        "        self.idx2char = {i: c for i, c in enumerate(self.vocab)}\n",
        "        self.encoded = [self.char2idx[c] for c in text]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encoded) - self.seq_length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.encoded[idx:idx + self.seq_length]\n",
        "        y = self.encoded[idx + 1:idx + self.seq_length + 1]\n",
        "        return torch.tensor(x), torch.tensor(y)\n",
        "\n",
        "class SimpleLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
        "        super(SimpleLSTM, self).__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x, hidden=None):\n",
        "        x = self.embed(x)\n",
        "        x, hidden = self.lstm(x, hidden)\n",
        "        x = self.fc(x)\n",
        "        return x, hidden\n",
        "\n",
        "# Hyperparameters\n",
        "text = \"Once upon a time in a land far, far away, there lived a wise old king. This king ruled over a prosperous kingdom filled with lush forests, sparkling rivers, and golden fields. The people of the kingdom were happy and content, for the king was kind and just. Every day, he would sit upon his throne and listen to the needs and concerns of his people.\\nOne day, a young traveler arrived at the palace gates. He carried a strange artifact that he claimed could reveal the future. The king, curious but cautious, invited the traveler to demonstrate this artifact's powers...\\n\"\n",
        "seq_length = 50\n",
        "batch_size = 32\n",
        "embed_dim = 64\n",
        "hidden_dim = 128\n",
        "epochs = 20\n",
        "\n",
        "dataset = SimpleDataset(text, seq_length)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "model = SimpleLSTM(len(dataset.vocab), embed_dim, hidden_dim)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training Loop\n",
        "for epoch in range(epochs):\n",
        "    hidden = None\n",
        "    for x, y in dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        output, hidden = model(x)\n",
        "        loss = criterion(output.view(-1, len(dataset.vocab)), y.view(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f\"Epoch {epoch + 1}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Text Generation\n",
        "def generate_text(model, start_str, length=100):\n",
        "    model.eval()\n",
        "    chars = [dataset.char2idx[c] for c in start_str]\n",
        "    input_seq = torch.tensor(chars).unsqueeze(0)\n",
        "    hidden = None\n",
        "    generated = start_str\n",
        "\n",
        "    for _ in range(length):\n",
        "        output, hidden = model(input_seq, hidden)\n",
        "        char_idx = torch.argmax(output[:, -1, :]).item()\n",
        "        generated += dataset.idx2char[char_idx]\n",
        "        input_seq = torch.tensor([[char_idx]])\n",
        "\n",
        "    return generated\n",
        "\n",
        "print(generate_text(model, start_str=\"The \", length=200))"
      ]
    }
  ]
}